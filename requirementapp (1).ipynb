{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe3b9df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36ad084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945093cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import lime\n",
    "from lime import lime_text\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743761c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LIME for text explanations\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be76116",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('PROMISE_exp1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082bfcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6df2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "def preprocess_text(text):\n",
    "  # Remove special characters and digits\n",
    "  text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "  # Convert to lowercase\n",
    "  text = text.lower()\n",
    "  # Tokenize the text\n",
    "  tokens = word_tokenize(text)\n",
    "  # Remove stopwords\n",
    "  tokens = [word for word in tokens if word not in stop_words]\n",
    "  # Join the tokens back into a single string\n",
    "  preprocessed_text = ' '.join(tokens)\n",
    "  preprocessed_text = text.lower() # Example: Convert text to lowercase\n",
    "\n",
    "  return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b59014e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# Define stop_words\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c84fec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to your text data\n",
    "raw_data['RequirementText'] = raw_data['RequirementText'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a2e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into features (X) and labels (y)\n",
    "X = raw_data['RequirementText']\n",
    "y = raw_data['_class_']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "529e1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode your labels if they are not already encoded\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a87dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenization and padding parameters\n",
    "max_words = 1000 # Maximum number of words to keep based on word frequency\n",
    "max_len = 100 # Maximum sequence length\n",
    "\n",
    "\n",
    "# Tokenize your text data\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16d8bde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define and compile your LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 64, input_length=max_len))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a96562bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of cross-validation folds\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db14fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store cross-validation accuracies\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d4aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X_padded, y):\n",
    "  X_train, X_test = X_padded[train_index], X_padded[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c50ddd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21d33337290>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21d33337290>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your model on the training data\n",
    "model.fit(X_train, y_train.astype('float'), epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b797fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 58ms/step\n",
      "7/7 [==============================] - 1s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = (model.predict(X_test) >= 0.5).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b970fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy and store it\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2446b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training and testing sets for final model training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "334ab7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21d39a10bd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21d39a10bd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your final model on the training data\n",
    "model.fit(X_train, y_train.astype('float'), epochs=10, batch_size=32, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dde287de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 76ms/step\n",
      "25/25 [==============================] - 2s 76ms/step\n",
      "7/7 [==============================] - 0s 62ms/step\n",
      "7/7 [==============================] - 0s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training and testing data\n",
    "y_pred_train = (model.predict(X_train) >= 0.5).astype('int')\n",
    "train_accuracy = accuracy_score(y_train.astype('int'), y_pred_train)\n",
    "\n",
    "y_pred_test = (model.predict(X_test) >= 0.5).astype('int')\n",
    "test_accuracy = accuracy_score(y_test.astype('int'), y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4d9ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion Matrix:\n",
      "[[ 80  12]\n",
      " [  0 102]]\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        92\n",
      "           1       0.89      1.00      0.94       102\n",
      "\n",
      "    accuracy                           0.94       194\n",
      "   macro avg       0.95      0.93      0.94       194\n",
      "weighted avg       0.94      0.94      0.94       194\n",
      "\n",
      "Train Confusion Matrix:\n",
      "[[343   9]\n",
      " [  3 420]]\n",
      "\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       352\n",
      "           1       0.98      0.99      0.99       423\n",
      "\n",
      "    accuracy                           0.98       775\n",
      "   macro avg       0.99      0.98      0.98       775\n",
      "weighted avg       0.98      0.98      0.98       775\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[ 80  12]\n",
      " [  0 102]]\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        92\n",
      "           1       0.89      1.00      0.94       102\n",
      "\n",
      "    accuracy                           0.94       194\n",
      "   macro avg       0.95      0.93      0.94       194\n",
      "weighted avg       0.94      0.94      0.94       194\n",
      "\n",
      "Train Confusion Matrix:\n",
      "[[343   9]\n",
      " [  3 420]]\n",
      "\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       352\n",
      "           1       0.98      0.99      0.99       423\n",
      "\n",
      "    accuracy                           0.98       775\n",
      "   macro avg       0.99      0.98      0.98       775\n",
      "weighted avg       0.98      0.98      0.98       775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrices and classification reports\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test.astype('int'), y_pred_test))\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test.astype('int'), y_pred_test))\n",
    "\n",
    "print(\"Train Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train.astype('int'), y_pred_train))\n",
    "print(\"\\nTrain Classification Report:\")\n",
    "print(classification_report(y_train.astype('int'), y_pred_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f65fd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LIME Text Explainer\n",
    "explainer = LimeTextExplainer(class_names=[\"F\", \"NF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5abecb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QPushButton, QTextBrowser, QFileDialog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abead337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a predict function that takes a list of texts as input\n",
    "def predict_function(texts):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "    # Tokenize and pad the preprocessed texts (assuming you have tokenizer and max_len defined)\n",
    "    X_seq = tokenizer.texts_to_sequences(preprocessed_texts)\n",
    "    X_padded = pad_sequences(X_seq, maxlen=max_len)\n",
    "\n",
    "    # Make predictions using your model (assuming model is defined)\n",
    "    predictions = model.predict(X_padded)\n",
    "\n",
    "    # Assuming your model returns a single label for each input, convert it to a probability distribution\n",
    "    # If your model returns probabilities directly, you can skip this step\n",
    "    predictions = np.column_stack([1 - predictions, predictions])  # Assuming binary classification\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1e35f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QPushButton, QTextBrowser, QFileDialog, QVBoxLayout, QWidget\n",
    "from PyQt5.QtGui import QFont, QIcon\n",
    "from PyQt5.QtCore import QSize\n",
    "# Add this import at the top of your code\n",
    "from PyQt5.QtGui import QFont\n",
    "from PyQt5.QtWidgets import QVBoxLayout, QWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "406e6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "class ExplanationApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize LIME Text Explainer\n",
    "        self.explainer = LimeTextExplainer(class_names=[\"F\", \"NF\"])\n",
    "\n",
    "        # Create a button to load and explain requirements\n",
    "        self.explain_button = QPushButton('Explain Requirements', self)\n",
    "        self.explain_button.clicked.connect(self.explain_requirements)\n",
    "        self.explain_button.setGeometry(10, 10, 180, 30)\n",
    "        \n",
    "        \n",
    "        # Set the CSS style of the button to change the hover effect to blue\n",
    "        self.explain_button.setStyleSheet(\"\"\"\n",
    "            QPushButton:hover {\n",
    "                background-color: blue;\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "        # Create a text browser to display the explanations\n",
    "        self.result_text = QTextBrowser(self)\n",
    "        self.result_text.setGeometry(10, 50, 780, 540)\n",
    "\n",
    "        self.setWindowTitle('Requirement Explanation App')\n",
    "        self.setGeometry(100, 100, 800, 600)\n",
    "\n",
    "    def explain_requirements(self):\n",
    "        # Open a file dialog to select the input text file\n",
    "        file_dialog = QFileDialog(self)\n",
    "        file_dialog.setFileMode(QFileDialog.ExistingFile)\n",
    "        file_dialog.setNameFilter(\"Text files (*.txt)\")\n",
    "        file_dialog.setViewMode(QFileDialog.List)\n",
    "        file_dialog.setOption(QFileDialog.ReadOnly, True)\n",
    "        file_dialog.setLabelText(QFileDialog.Accept, \"Load\")\n",
    "        file_dialog.setWindowTitle(\"Select a text file\")\n",
    "        file_path, _ = file_dialog.getOpenFileName()\n",
    "\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        # Read and preprocess requirements from the selected file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        explanations = []\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            preprocessed_text = preprocess_text(line)\n",
    "            preprocessed_text = preprocessed_text.lower()\n",
    "            preprocessed_text = ' '.join([word for word in preprocessed_text.split() if word not in stop_words and len(word) > 2])\n",
    "\n",
    "            # Get predicted probabilities using your predict_function\n",
    "            predicted_probabilities = predict_function([preprocessed_text])\n",
    "\n",
    "            # Get the predicted class label\n",
    "            predicted_label = label_encoder.classes_[np.argmax(predicted_probabilities)]\n",
    "\n",
    "            # Explain the prediction for the current requirement\n",
    "            explanation = self.explainer.explain_instance(preprocessed_text, predict_function, num_features=10, num_samples=num_samples)\n",
    "\n",
    "            explanations.append(f\"Requirement {i + 1} Text: {line}\\n\")\n",
    "            explanations.append(f\"Predicted Class Label: {predicted_label}\\n\")\n",
    "            explanations.append(f\"Explanation:\\n{explanation.as_list()}\\n\")\n",
    "            explanations.append(\"=\" * 50)\n",
    "\n",
    "        self.setStyleSheet(\n",
    "    \"\"\"\n",
    "    QMainWindow {\n",
    "        background-color: #f2f2f2;\n",
    "    }\n",
    "\n",
    "    QPushButton {\n",
    "        background-color: #007BFF;\n",
    "        color: white;\n",
    "        border: none;\n",
    "        border-radius: 5px;\n",
    "    }\n",
    "\n",
    "    QPushButton:hover {\n",
    "                background-color: blue;\n",
    "            }\n",
    "\n",
    "    QTextBrowser {\n",
    "        background-color: white;\n",
    "        color: black;\n",
    "        border: 1px solid #ccc;\n",
    "        border-radius: 5px;\n",
    "        font-family: Arial;\n",
    "        font-size: 12pt;\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "        # Example of adding an icon to a button\n",
    "        self.explain_button.setIcon(QIcon(\"icon.png\"))\n",
    "        \n",
    "        # Create a central widget\n",
    "        central_widget = QWidget(self)\n",
    "        self.setCentralWidget(central_widget)\n",
    "\n",
    "        # Create a vertical layout for the central widget\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.explain_button)\n",
    "        layout.addWidget(self.result_text)\n",
    "        central_widget.setLayout(layout)\n",
    "\n",
    "\n",
    "        # Display the explanations in the text browser\n",
    "        self.result_text.clear()\n",
    "        self.result_text.setPlainText(\"\".join(explanations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9194714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    app = QApplication(sys.argv)\n",
    "    ex_app = ExplanationApp()\n",
    "    ex_app.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fa5ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "32/32 [==============================] - 2s 69ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "32/32 [==============================] - 2s 74ms/step\n",
      "32/32 [==============================] - 2s 74ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "32/32 [==============================] - 2s 64ms/step\n",
      "32/32 [==============================] - 2s 64ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "32/32 [==============================] - 2s 62ms/step\n",
      "32/32 [==============================] - 2s 62ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "32/32 [==============================] - 2s 63ms/step\n",
      "32/32 [==============================] - 2s 63ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "32/32 [==============================] - 2s 61ms/step\n",
      "32/32 [==============================] - 2s 61ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "32/32 [==============================] - 2s 63ms/step\n",
      "32/32 [==============================] - 2s 63ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "32/32 [==============================] - 2s 72ms/step\n",
      "32/32 [==============================] - 2s 72ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "32/32 [==============================] - 2s 62ms/step\n",
      "32/32 [==============================] - 2s 62ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "32/32 [==============================] - 2s 63ms/step\n",
      "32/32 [==============================] - 2s 63ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "32/32 [==============================] - 2s 63ms/step\n",
      "32/32 [==============================] - 2s 63ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "32/32 [==============================] - 2s 61ms/step\n",
      "32/32 [==============================] - 2s 61ms/step\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3450: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n",
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3450: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c89d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
